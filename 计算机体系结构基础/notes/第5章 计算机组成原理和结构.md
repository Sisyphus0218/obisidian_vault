#计算机体系结构-硬件结构
## 5.1 冯·诺依曼结构
##### 主要特点
1. 计算机由存储器、运算器、控制器、输入设备和输出设备五部分组成，其中运算器和控制器合称为中央处理器 CPU。 
2. 存储器是按地址访问的线性编址的一维结构，每个单元的位数固定。 
3. 采用存储程序方式，即指令和数据不加区别混合存储在同一个存储器中。
4. 控制器通过执行指令发出控制信号控制计算机的操作。指令在存储器中按其执行顺序存放，由指令计数器指明要执行的指令所在的单元地址。指令计数器一般按顺序递增，但执行顺序可按运算结果或当时的外界条件而改变。 
5. 以运算器为中心，输入输出设备与存储器之间的数据传送都经过运算器。

改进 
1. 由以运算器为中心改进为以存储器为中心。使数据的流向更加合理，从而使运算器、存储器和输入输出设备能够并行工作。 
2. 由单一的集中控制改进为分散控制。计算机发展初期，工作速度很低，运算器、存储器、控制器和输入输出设备可以在同一个时钟信号的控制下同步工作。现在运算器、内存与输入输出设备的速度差异很大，需要采用异步方式分散控制。 
3. 从基于串行算法改进为适应并行算法。出现了流水线处理器、超标量处理器、向量处理器、多核处理器、对称多处理器 (Symmetric Multiprocessor，简称 SMP)、大规模并行处理机 (Massively Parallel Processing，简称 MPP) 和机群系统等。 
4. 出现为适应特殊需要的专用计算机，如图形处理器 (Graphic Processing Unit，简称GPU)、数字信号处理器 (Digital Signal Processor，简称 DSP) 等。 
5. 在非冯·诺依曼计算机的研究方面也取得一些成果，如依靠数据驱动的数据流计算机、图归约计算机等。

变种——哈佛结构
哈佛结构把程序和数据分开存储。控制器使用两条独立的总线读取程序和访问数据，程序空间和数据空间完成分开。 
在通用计算机领域，由于应用软件的多样性，要求计算机不断地变化所执行的程序内容，并且频繁地对数据与程序占用的存储器资源进行重新分配，使用统一编址可以最大限度地利用资源。 
在嵌入式应用中，系统要执行的任务相对单一，程序一般是固化在硬件里的，同时嵌入式系统对安全性、可靠性的要求更高，哈佛结构独立的程序空间更有利于代码保护。 
因此，在嵌入式领域，哈佛结构得到了广泛应用；哈佛结构并没有改变冯·诺依曼结构存储程序和指令驱动执行的本质，只是冯·诺依曼结构的一个变种。

## 5.2 计算机的组成部件
### 5.2.1 运算器
略

### 5.2.2 控制器
常见的提高流水线效率的技术包括转移预测技术、乱序执行技术、超标量 (又称为多发射) 技术等。

##### 转移预测技术 
1. 转移预测器根据当前转移指令或其他转移指令的历史行为，在转移指令的取指或译码阶段预测该转移指令的跳转方向和目标地址并进行后续指令的取指。 
2. 转移指令执行后，根据已经确定的跳转方向和目标地址对预测结果进行修正。 
3. 如果发生转移预测错误，需要取消指令流水线中的后续指令。

eg. 在取指部件中设置一位标志记录上一条转移指令的跳转方向，碰到转移指令，不用等该转移指令执行结果，就根据该标志猜测跳转方向进行取指。 
``for(i=0; i<N; i++)`` 类的循环，这种简单的转移猜测可以达到 (N-1) / (N+1) 的准确度，当 N 很大时准确度很高。

##### 乱序执行技术
如果指令 i 是条长延迟指令，如除法指令或 Cache 不命中的访存指令，那么在顺序指令流水线中指令 i 后面的指令需要在流水线中等待很长时间。 
乱序执行技术：通过指令动态调度允许指令 i 后面的源操作数准备好的指令越过指令 i 执行 (需要使用指令 i 的运算结果的指令由于源操作数没有准备好，不会越过指令 i 执行)，以提高指令流水线效率。 
为此，在指令译码之后的读寄存器阶段，应判断指令需要的操作数是否准备好。 
1. 如果操作数已经准备好，就进入执行阶段； 
2. 如果操作数没有准备好，就进入称为保留站或者发射队列的队列中等待，直到操作数准备好后再进入执行阶段。 

为了保证执行结果符合程序规定的要求，乱序执行的指令需要有序结束。
1. 执行完的指令均进入一个称为重排序缓冲 ROB (Re- Order Buffer) 的队列，并把执行结果临时写入重命名寄存器。
2. ROB 根据指令进入流水线的次序，有序提交指令的执行结果到目标寄存器或存储器。 

乱序执行流水线把指令执行结果写入重命名寄存器而不是结构寄存器，以避免破坏结构寄存器的内容，到顺序提交阶段再把重命名寄存器内容写入结构寄存器。 
两组执行不同运算但使用同一结构寄存器的指令可以使用不同的重命名寄存器，从而避免该结构寄存器成为串行化瓶颈，实现并行执行。

保留站、重排序缓冲：临时存储指令以使指令在流水线中流动更加通畅
重命名寄存器：临时存储数据以使数据在流水线流动更加通畅。 
保留站：把指令从有序变为无序以提高执行效率
重排序缓存：把指令从无序重新变为有序以保证正确性
重命名寄存器：在乱序执行过程中临时存储数据。 
保留站、 重排序缓冲、 重命名寄存器都是微结构中的数据结构，程序员无法用指令来访问，是结构设计人员为了提高流水线效率而用来临时存储指令和数据的。 

##### 超标量技术
超标量结构允许指令流水线的每一阶段同时处理多条指令。
超标量结构的指令和数据通路都变宽了，故寄存器端口、保留站端口、ROB 端口、功能部件数都需要增加。
现代超标量处理器一般包含两个以上访存部件，两个以上定点运算部件及两个以上浮点运算部件。
超标量结构在指令译码或寄存器重命名时不仅要判断前后拍指令的数据相关，还需要判断同一拍中多条指令间的数据相关。

### 5.2.3 存储器
##### 存储系统
存储系统分为高速缓存 (Cache)、 主存储器和辅助存储器三个层次。 
1. Cache：存放当前 CPU 最频繁访问的部分主存储器内容，可以采用比 DRAM 速度快但容量小的静态随机访问存储器 (Static Random Access Memory，简称 SRAM) 实现。 
2. 存储器：存储程序和数据，又称主存储器或内存，一般用动态随机访问存储器 (Dynamic Random Access Memory，简称 DRAM) 实现。
3. 辅助存储器：使用磁盘、 磁带、 光盘等能存储大量数据的存储器。
现代计算机中还有少量只读存储器 (Read Only Memory，简称ROM) 用来存放引导程序和基本输入输出系统 (Basic Input Output System，简称 BIOS) 等。 

##### 存储器的主要评价指标
存储容量：存储容量越大，可以存放的程序和数据越多。 
访问速度：访问速度越快，处理器访问的时间越短。 

##### 存储介质
1. 磁性存储介质：如硬盘、 磁带等，存储密度高、成本低、具有非易失性。缺点是访问速度慢。
2. 闪存 (Flash Memory)：非易失性的存储介质，与磁盘相比，它们的访问速度快，成本高，容量小。 随着闪存工艺技术的进步，闪存芯片的集成度不断提高，成本持续降低，闪存正在逐步取代磁盘作为计算机尤其是终端的辅助存储器。
3. 动态随机访问存储器 (DRAM)：易失性存储器。存储密度较高 (存储一位数据只需一个晶体管)，需要周期性刷新，访问速度较快。其访问速度一般在几十纳秒级。
4. 静态随机访问存储器 (SRAM)：易失性存储器。 存储密度不如 DRAM 高 (SRAM 存储一位数据需要 4~8 个晶体管)，不用周期性刷新，但访问速度比DRAM 快，可以达到纳秒级。

##### 存储层次
存储层次的有效性，依赖于程序的访存局部性原理
1. 时间局部性：如果一个数据被访问，那么在短时间内很有可能被再次访问；
2. 空间局部性：指的是如果一个数据被访问，那么它的邻近数据也很有可能被访问。
利用局部性原理，可以把程序近期可能用到的数据存放在靠上的层次，把近期内不会用到的数据存放在靠下的层次。  
现代计算机一般使用多端口寄存器堆实现寄存器，使用 SRAM 来构建片上的高速缓存 (Cache)，使用 DRAM来构建程序的主存储器 (也称为主存、内存)，使用磁盘或闪存来构建大容量的存储器。
![[Pasted image 20221207150750.png]]

##### 高速缓存
CPU 执行一个程序的时间 = 程序中的指令数 / IPC×时钟周期。 
IPC = 运算指令IPC×运算指令的比例 + 访存指令IPC×访存指令的比例
访存指令的 IPC 为平均访问延迟 AMAT (Average Memory Access Latency) 的倒数。 
AMAT = HitTime + MissRate×MissPenalty
HitTime：高速缓存命中时的访问延迟；MissRate：高速缓存失效率；MissPenalty：高速缓存失效时额外的访问延迟。 
例如，某计算机系统 HitTime=1，MissRate=5%，MissPenalty=100，则 AMAT=1+5=6。

##### 内存
现代计算机的内存一般都采用同步动态随机存储器 (SDRAM) 实现。 
DRAM 的一个单元由 MOS 管 T 和电容 C (存储单元) 组成。
C 存储的电位决定存储单元的逻辑值。 
字线：根据读写地址译码得到，连接同一字的若干位；
位线：把若干字的同一位链接在一起。 

读操作：先把位线预充到 Vref = VCC / 2，然后字线打开 T 管，C 引起差分位线微小的电位差，感应放大器读出，读出后 C 中的电位被破坏，需要把读出值重新写入 C。
写操作：先把位线预充成要写的值，然后打开字线，把位线的值写入 C。 
C 中的电容可能会漏掉，因此 DRAM 需要周期刷新，刷新可以通过读操作进行，一般每行几十微秒刷新一次。

![[Pasted image 20221207152520.png]]

SDRAM 芯片一般采用行列地址线复用技术。
对 SDRAM 进行读写时，需要先发送行地址打开一行，再发送列地址读写需要访问的存储单元。 
为了提高访问的并发度，SDRAM 芯片一般包含多个 Bank (存储块)，这些 Bank 可以并行操作。 

对 SDRAM 进行写操作后，由于必须等到写数据从 IO 引脚传送到对应 Bank 的感应放大器后，才能进行后续的预充电操作 (针对相同 Bank) 或者读操作 (针对所有 Bank)，因此写操作会给后续的其他操作带来较大的延迟，但连续的写操作却可以流水执行。为了降低写操作带来的开销，内存控制器往往将多个写操作聚集在一起连续发送，以分摊单个写操作的开销。

**影响 SDRAM 芯片读写速度的因素**
1. 行缓冲局部性
SDRAM 芯片的一行数据在从存储体中读出后，存储体中的值被破坏，保存在对应的一组感应放大器中，这组感应放大器也被称为行缓冲。 
如果下一个访存请求访问同一行的数据 (命中行缓冲)：直接从该感应放大器中读出，而不需要重新访问存储体内部，降低 SDRAM 的访问延迟。 
如果行缓冲不命中：首先将行缓冲中的数据写回存储体，再将下一行读出到行缓冲中进行访问。  ^fff346
 
- 关行 (Close Page) 策略：每次读写完后先把行缓冲的内容写入存储体，才能进行下一次读写，每次读写的延迟是确定的。 
- 开行 (Open Page) 策略：每次读写完后不把行缓冲的内容写入存储体。
	- 如果下一次读写时所读写的数据在行缓冲中 (称为行命中)：直接对行缓冲进行读写即可，延迟最短；
	- 如果下一次读写时所读写的数据不在行缓冲中：需要先将行缓冲中的数据写回对应的行，再将新地址的数据读入行缓冲，再进行读写，延迟最长。 
因此，
- 如果内存访问的局部性好，可以采用开行策略。
- 如果内存访问的局部性不好，可以采用关行策略。 
内存控制器可以通过对多个访存请求进行调度，尽量把对同一行的访问组合在一起，以增加内存访问的局部性。

2. Bank 级并行度
SDRAM 芯片包含的多个 Bank 是相互独立的，它们可以同时执行不同的操作。
比如，对 Bank 0 激活的同时，可以对 Bank 1 发出预充电操作。访问不同 Bank 的多个操作可以并行执行。Bank 级并行度可以降低冲突命令的等待时间，容忍单个 Bank 访问的延迟。

利用内存的这两个特性，可以在内存控制器上对并发访问进行调度，降低读写访问的平均延迟，提高内存的有效带宽。 

### 5.2.4 输入/ 输出设备
##### GPU
GPU (Graphics Processing Unit，图形处理单元) 是与CPU联系最紧密的外设之一，主要用来处理2D和3D的图形、图像和视频，以支持基于视窗的操作系统、图形用户界面、视频游戏、可视化图像应用和视频播放等。

GPU最早是作为一个独立的板卡出现的，所以称为显卡。我们常说的独立显卡和集成显卡是指GPU是作为一个独立的芯片出现还是被集成在芯片组或处理器中。

CPU将需要显示的原始数据放在内存中，让GPU通过DMA的方式读取数据，经过解析和运算，将结果写至显存中，再由显示控制器读取显存中的数据并输出显示。

将GPU与CPU集成至同一个处理器芯片时，CPU与GPU内存一致性维护的开销和数据传递的延迟都会大幅降低。此时系统内存需要承担显大幅增加，因为图形应用具有天生的并行性，GPU可以轻松地耗尽有限的内存带宽。

##### 硬盘
磁性材料
1. 磁性材料具有断电记忆功能，可以长时间保存数据；
2. 磁性材料的存储密度高，可以搭建大容量存储系统；
3. 磁性材料的成本很低。
硬盘就是一种磁性存储介质。

构造原理：将磁性材料覆盖在盘片上，通过一个读写头(磁头)悬浮在碟片表面来感知存储的数据。通过碟片的旋转和磁头的径向移动来读写碟片上任意位置的数据。

碟片被划分为多个环形的轨道 (称为磁道，Track) 来保存数据。
每个磁道又被分为多个等密度 (等密度数据) 的弧形扇区 (Sector) 作为存储的基本单元。
硬盘在工作时，盘片是一直旋转的，当想要读取某个扇区的数据时，首先要将读写头移动到该扇区所在的磁道上，当想要读写的扇区旋转到读写头下时，读写头开始读写数据。

衡量磁盘性能的指标包括响应时间和吞吐量，也就是延迟和带宽。
寻道时间：磁头移动到目标磁道的时间称为寻道时间。
旋转时间：当磁头移动到目标磁道后，等待目标扇区旋转到磁头下面的时间。
传输时间：扇区旋转到目标位置后，传输这个扇区的数据需要的时间。

旋转时间与盘片的旋转速度有关。

传输时间是扇区大小、旋转速度和磁道记录密度的函数。磁盘是由磁盘控制器控制的。磁盘控制器控制磁头的移动、接触和分离以及磁盘和内存之间的数据传输。

通过IO操作访问磁盘控制器又会引入新的时间。现在的磁盘内部一般都会包含一个数据缓冲，读写磁盘时，如果访问的数据正好在缓冲中命中，则不需要访问磁盘扇区。

当有多个命令读写磁盘时，还需要考虑排队延迟。

##### 闪存
闪存 (Flash Storage) 是一种半导体存储器，非易失性，访问延迟却只有磁盘的千分之一到百分之一，而且它尺寸小、功耗低，抗震性更好。

SSD固态硬盘是使用闪存构建的大容量存储设备，它模拟硬盘接口，可以直接通过硬盘的SATA总线与计算机相连。

最早出现的闪存被称为NOR型闪存，因为它的存储单元与一个标准的或非门很像。
NAND型闪存采用另一种技术，它的存储密度更高，每GB的成本更低，因此NAND型闪存适合构建大容量的存储设备。前面所列的SD卡、U盘和SSD固态硬盘一般都是用NAND型闪存构建的。

使用闪存技术构建的永久存储器的问题：闪存的存储单元随着擦写次数的增多存在损坏的风险。
解决：大多数NAND型闪存产品内部的控制器采用地址块重映射的方式来分布写操作，目的是将写次数多的地址转移到写次数少的块中。该技术被称为磨损均衡(Wear Leveling)。

## 5.3 计算机系统硬件结构发展
随着应用需求的变化和工艺水平的不断提升，冯·诺依曼结构中
1. 控制器和运算器逐渐演变为计算机系统中的中央处理器部分；
2. 输入、输出设备统一通过北桥和南桥与中央处理器连接；
3. 中央处理器中的图形处理功能从中央处理器中分化出来形成专用的图形处理器。
因此，现代计算机系统的硬件结构主要包括了中央处理器、图形处理器、北桥及南桥等部分。

中央处理器 (CPU) 主要包含控制器和运算器，在发展的过程中不断与其他部分融合。传统意义上的中央处理器在处理器芯片中更多地体现为处理器核，现代的处理器芯片上往往集成多个处理器核。

图形处理器 (GPU) 是一种面向 2D 和 3D 图形、视频、可视化计算和显示优化的处理器。作为人机交互的重要界面，GPU 在计算机体系结构发展的过程中，担任了越来越重要的角色。除了对图形处理本身之外，还开始担负科学计算加速器的任务。

北桥 (North Bridge) 是离 CPU 最近的芯片，主要负责控制显卡、内存与 CPU 之间的数据交换，向上连接处理器，向下连接南桥。

南桥 (South Bridge) 主要负责硬盘、键盘以及各种对带宽要求较低的 IO 接口与内存、CPU 之间的数据交换。

### 5.3.1 CPU-GPU-北桥-南桥四片结构
CPU (处理器) 芯片、北桥芯片和南桥芯片一般是直接以芯片的形式安装或焊接在计算机主板上，而 GPU 则以显卡的形式安装在计算机主板的插槽上。计算机的各个部件根据速度快慢以及与处理器交换数据的频繁程度被安排在北桥和南桥中。

CPU 通过处理器总线 (也称系统总线) 和北桥直接相连，北桥再通过南北桥总线和南桥相连，GPU 一般以显卡的形式连接北桥。 

内存控制器集成在北桥芯片中，硬盘接口、USB 接口、网络接口、音频接口以及鼠标、键盘等接口放在南桥芯片中。在北桥上还会提供各种扩展接口用于其他功能卡的连接。 

### 5.3.2 CPU-北桥-南桥三片结构
GPU 功能被集成到北桥, 即一般所说的集成显卡。

CPU 通过处理器总线和北桥直接相连，北桥再通过南北桥总线和南桥相连。 

内存控制器、显示功能以及高速 IO 接口 (如 PCIE 等) 集成在北桥芯片中，硬盘接口、USB 接口、网络接口、音频接口以及鼠标、键盘等接口部件放在南桥芯片中。

### 5.3.3 CPU-弱北桥-南桥三片结构
对计算机系统性能影响显著的内存控制器开始被集成到 CPU 芯片中，从而大幅降低了内存访问延迟, 提升了内存访问带宽，这在一定程度上缓解了存储墙问题。

北桥的功能被弱化，主要集成了 GPU、显示接口、高速 IO 接口 (例如 PCIE 接口等)。

### 5.3.4 CPU-南桥两片结构
图形处理器也开始被集成到 CPU 芯片中，北桥存在的必要性就进一步降低，开始和南桥合二为一。

CPU 芯片集成处理器核、内存控制器和 GPU 等主要部件，对外提供显示接口、内存接口等、并通过处理器总线和南桥相连。 
南桥芯片包含硬盘、USB、网络控制器以及 PCIE/PCI、LPC 等总线接口。

由于 GPU 和 CPU 都需要大量访问内存，会带来一些访存冲突，而且相对来说，GPU 对于实时性的要求更高，即访存优先级会更高一些，这在一定程度上会影响 CPU 的性能。 实际上，处理器中集成的 GPU 性能相比独立显卡中的 GPU 性能会稍弱。

有一些两片结构是将 GPU 集成在南桥芯片中。这样在南桥上可以实现独立的显存供 GPU 使用，这在某些条件下更有利于 GPU 性能的发挥，且 CPU 升级时带来的开销会更小。

### 5.3.5 SoC 单片结构
在单个芯片上集成了处理器、 内存控制器、 GPU 以及硬盘、 USB、网络等 IO 接口。

单片 SoC 结构的集成度更高，功耗控制方法更加灵活，有利于系统的小型化和低功耗设计。 
但系统的扩展性没有多片结构好，升级的开销也更大。 

目前，主流商用处理器中面向中高端领域的处理器普遍采用两片结构，而面向中低端及嵌入式领域的处理器普遍采用单片结构。SoC 单片结构最常见的是在手机等移动设备中。

## 5.4 处理器和 IO 设备间的通信
IO设备一般都是由一个设备控制器进行控制。设备控制器会提供一组寄存器接口，寄存器的内容变化会引起设备控制器执行一系列复杂的动作。设备控制器的接口寄存器也被称为IO寄存器。

处理器通过读写IO寄存器来访问设备。写入这些寄存器的数据，会被设备控制器解析成命令，因此有些情况下将处理器对IO寄存器的访问称为命令字。

### 5.4.1 IO 寄存器寻址
为了访问 IO 寄存器, 处理器必须能够寻址这些寄存器。 
IO 寄存器的寻址方式有两种：内存映射 IO 和特殊 IO 指令。

内存映射 IO：把 IO 寄存器的地址映射到内存地址空间中，这些寄存器和内存存储单元被统一编址。 读写 IO 地址和读写内存地址使用相同的指令来执行。 处理器需要通过它所处的状态来限制应用程序可以访问的地址空间，使其不能直接访问 IO 地址空间，从而保证应用程序不能直接操作 IO 设备。 

特殊 IO 指令：使用专用指令来执行 IO 操作。 因此，IO 地址空间可以和内存地址空间重叠，但实际指向不同的位置。 操作系统可以通过禁止应用程序执行 IO 指令的方式来阻止应用程序直接访问 IO 设备。

### 5.4.2 处理器和 IO 设备之间的同步
##### 查询
查询：处理器向 IO 设备发出访问请求后，不断读取 IO 设备的状态寄存器，也被称为轮询。

eg. 打印机
打印机控制器会提供两个寄存器：数据寄存器和状态寄存器。 
- 数据寄存器：存放当前需要打印的数据。
- 状态寄存器：指示打印机的状态。
	- 完成位：表示上一个字符打印完毕，可以打印下一个字符。
	- 错误位：在打印机出现异常时指示出错的状态，比如卡纸或者缺纸。 

处理器在打印一串数据时，
1. 把数据写入数据寄存器；
2. 不断读取状态寄存器的值：
	1. 当完成位=1，才能把下一个字符写入数据寄存器。 
	2. 检查错误位的值，当发生错误时，去执行对应的错误处理程序。

由于 IO 设备的速度一般都较慢，使用查询方式会浪费处理器的指令周期。执行轮询的处理器无法同时执行其他工作，造成了性能的浪费。

##### 中断
中断：处理器不需要轮询状态寄存器的值，而是在等待设备完成某个操作时转去执行其他进程。 
当设备完成某个操作后，自行产生一个中断信号来中断处理器的执行。处理器被中断后，再去读取设备的状态寄存器。 
中断方式将处理器从等待 IO 中解放了出来，大大提高了处理器的利用率。

中断本质上是 IO 设备对处理器发出的一个信号，让处理器知道此时有数据传输需要或者已经发生数据传输。CPU 收到中断信号后，会暂停当前 CPU 的执行进程，转去执行某个特定的程序。 

中断的一般过程：
1. 中断源发出中断信号到中断控制器；
2. 中断控制器产生中断请求给 CPU；
3. CPU 发出中断响应, 并读取中断类型码；
4. CPU 根据中断类型码执行对应的中断服务程序；
5. CPU 从中断服务程序返回，中断结束。

中断源：中断的源头，比如用户敲击一下键盘，单击一下鼠标，或者 DMA 的一次传输完成了，对应的控制器会产生一个中断信号。 
中断信号：可以是一根信号线，也可以是一个消息包。中断信息会传送到中断控制器中。 
中断控制器：负责中断汇集、 记录和转发的硬件逻辑。典型的中断控制器如 Intel 的 8259A。 

8259A 内部包含 3 个寄存器
1. 中断请求寄存器 ( Interrupt Request Register，简称 IRR)：存放当前的中断请求；
2. 中断在服务寄存器 ( In-Service Register，简称 ISR)：存放当前CPU 正在服务的中断请求；
3. 中断 Mask 寄存器 ( Interrupt Mask Register，简称 IMR)：存放中断屏蔽位。

1. 当中断源产生中断信号后，会将中断请求寄存器的某一位设置为 1，如果该位没有被屏蔽，则产生一个中断信号 (比如中断线) 给处理器。 
2. 处理器检测到该中断信号，并跳转到固定的地址执行中断服务例程。 
3. 在中断服务例程中，处理器通过读取 8259A 获得中断向量号，进而调用对应的中断服务程序。 
4. 在中断服务程序返回之前，要保证本次中断的中断信号被清除掉，否则 CPU 从中断服务程序返回之后，会被再次触发中断。 8259A 在中断响应时会自动将 IRR 的对应位复位。 
	1. 对于电平触发的中断，中断服务程序一般会读写中断源的相关寄存器，从而保证在中断返回之前，中断源的中断信号被撤掉，这样 8259A 的中断请求寄存器的对应位不会被再次置位。 
	2. 对于脉冲触发的中断，则不需要对设备 IO 寄存器进行处理。

### 5.4.3 存储器和 IO 设备之间的数据传送
存储器和 IO 设备之间需要进行大量的数据传输。

##### PIO (Programming Input / Output) 模式
存储器和 IO 设备之间没有直接的数据通路，存储器和 IO 设备之间的数据传送由处理器来完成。
数据从存储器到 IO ：处理器从存储器中读数据到通用寄存器，再从通用寄存器写数据到 IO 设备。 
数据从 IO 到存储器：处理器从 IO 设备中读数据到通用寄存器，再从通用寄存器写入内存。 
由于 IO 访问的访问延迟一般较大，且访问之间需要严格的顺序关系，故 PIO 方式的带宽较低。 

PIO 同步方式：查询方式和中断方式。 
虽然中断方式可以降低处理器查询的开销，但当进行大量数据传输时，PIO 模式仍然需要占用大量的处理器时间。 
使用中断方式，每传送一定的数据后都要进入一次中断，在中断服务程序中真正用于数据传送的时间可能并不多，大量的时间被用于断点保护、中断向量查询、现场恢复、中断返回等辅助性工作。对于一些数据传送速率较快的设备，PIO 方式可能会因为处理器搬运数据速度较慢而降低数据的传送速度，因此 PIO 方式一般用于键盘、鼠标等低速设备。
在 PIO 方式中, 数据要经过处理器内部的通用寄存器进行中转。中转不仅影响处理器的执行，也降低了数据传送的速率。 

直接存储器访问  DMA (Direct Memory Access) 方式
在存储器和 IO 设备之间开辟一条数据通道，专门用于数据传输，将处理器从数据搬运中解放出来。 数据传送由专门的硬件来控制，称为 DMA 控制器。

##### DMA传输过程
1. 处理器为 DMA 请求预先分配一段地址空间。
2. 处理器设置 DMA 控制器参数。这些参数包括设备标识、数据传送的方向、内存中用于数据传送的源地址或目标地址、传输的字节数量等。
3. DMA 控制器进行数据传输。DMA 控制器发起对内存和设备的读写操作，控制数据传输。DMA 传输相当于用 IO 设备直接续写内存。
4. DMA 控制器向处理器发出一个中断，通知处理器数据传送的结果 (成功或者出错以及错误信息)。
5. 处理器完成本次 DMA 请求，可以开始新的 DMA 请求。

DMA 方式对于存在大量数据传输的高速设备是一个很好的选择，硬盘、网络、 显示等设备普遍都采用 DMA 方式。 

PIO 和 DMA 两种数据传输方式的不同：
![[Pasted image 20221207194638.png]]
PIO 方式和 DMA 方式处理的流程一致，区别在于：
1. 键盘的数据是被记录在 IO 设备本身的, 而网卡的数据则直接由网卡写入内存之中；
2. CPU 处理时，对键盘是直接从 IO 寄存器读数据，而对网卡则直接从内存读数据。
看起来似乎差别不大，但需要考虑的是，IO 访问相比内存访问慢很多，而且对于内存访问，CPU 可以通过 Cache、预取等方式进行加速，IO 访问则缺少这种有效的优化方式。 
如果网卡采用 PIO 的方式使用 CPU，对网卡的包一个字一个字地进行读访问，效率将非常低下。 
而对于键盘来说，一次输入仅仅只有 8 位数据，而且相比处理器的处理速度，键盘输入的速度相当低，采用 PIO 的处理方式能够很简单地完成数据输入任务。