#计算机体系结构-微结构
## 9.1 单周期处理器
略

## 9.2 流水线处理器 
略

## 9.3 指令相关和流水线冲突 
指令间的相关可以分为 3 类：数据相关、控制相关和结构相关。 
1. 数据相关：两条指令访问同一个寄存器或内存单元，而且这两条指令中至少有 1 条是写该寄存器或内存单元的指令。
2. 控制相关：两条指令中一条是转移指令且另一条指令是否被执行取决于该转移指令的执行结果。
3. 结构相关：两条指令使用同一份硬件资源。

### 9.3.1 数据相关引发的冲突及解决办法 
1. 写后读 (RAW) 相关：后面指令要用到前面指令所写的数据，也称为真相关。
2. 写后写 (WAW) 相关：两条指令写同一个单元，也称为输出相关。 
3. 读后写 (WAR) 相关：后面的指令覆盖前面指令所读的单元，也称为反相关。
5 级简单流水线中，只有 RAW 相关会引起流水线冲突。
乱序执行流水线中，WAR 相关和 WAW 相关也有可能引起流水线冲突。

##### RAW 相关
下面重点分析 RAW 相关所引起的流水线冲突。对于如下指令序列

```
add.w $r2, $r1, $r1
add.w $r3, $r2, $r2
ld.w  $r4, $r3, 0
add.w $r5, $r4, $r4
```

5 级简单流水线处理器中执行的流水线时空图如图 9.9 所示。第 2 条指令会在第 1 条指令写回寄存器之前读取寄存器，从而引发数据错误。 
![[Pasted image 20221210184021.png]]

##### 阻塞
让第 2 条指令在译码阶段等待 (阻塞) 3 拍，直到第 1 条指令将结果写入寄存器后才能读取寄存器。 
![[Pasted image 20221210184138.png]]

具体电路实现：将被阻塞流水级所在的寄存器保持原值不变，同时向被阻塞流水级的下一级流水级输入指令无效信号，用流水线空泡 (Bubble) 填充。处理器部件的角度时空图如下。
![[Pasted image 20221210184154.png]]

##### 流水线前递技术
阻塞势必引起流水线执行效率的降低, 为此需要更为高效的解决方式。 
前递：在流水线中读取指令源操作数的地方通过多路选择器直接把前面指令的运算结果作为后面指令的输入。
加法指令在执行级就完成了运算，因此能够设计一条通路，将这个结果前递至读寄存器的地方，即有一条从执行级到译码级的前递通路。还可以依次添加从访存级、写回级到译码级的前递通路。 
![[Pasted image 20221210184420.png]]

### 9.3.2 控制相关引发的冲突及解决办法 
控制相关引发的冲突本质上是对程序计数器 PC 的冲突访问引起的。
![[Pasted image 20221210184859.png]]
执行阶段 R2 触发器所存储的值经过计算之后才能给出转移指令的正确目标并在下一个时钟上升沿更新 PC，但转移指令尚未执行结束时，PC 已经更新完毕并取指，从而可能导致取回了错误的指令。 

法1：通过在取指阶段引入 2 拍的流水线阻塞来解决。
![[Pasted image 20221210185216.png]]

法2：增加专用的运算资源将转移指令条件判断和计算下一条指令 PC 的处理调整到译码阶段，转移指令后面的指令只需要在取指阶段等 1 拍。
![[Pasted image 20221210185200.png]]

为更进一步减少由控制相关引起的阻塞，可以采用转移指令的延迟槽技术，在定义指令系统的时候就明确转移指令延迟槽指令的执行不依赖于转移指令的结果，这样转移指令后面的指令在取指阶段 1 拍也不用等。 总之，在单发射 5 级静态流水线处理器中，通过在译码阶段对转移指令进行处理和利用转移指令延迟槽技术，就可以避免控制相关引起的流水线阻塞。但是这两项技术并不一定适用于其他结构。

### 9.3.3 结构相关引发的冲突及解决办法 
结构相关引起冲突的原因是两条指令要同时访问流水线中的同一个功能部件。

## 9.4 流水线与异常处理
异常产生的来源包括：外部事件、指令执行中的错误、数据完整性问题、地址转换异常、系统调用和陷入以及需要软件修正的运算等。 
在流水线处理器中，这些不同类型的异常可能在流水线的不同阶段产生。
eg. 访存地址错异常可以在取指阶段和访存阶段产生，保留指令异常和系统调用异常在译码阶段产生，整数溢出异常在执行阶段产生，而中断则可以在任何时候发生。

异常可以分为可恢复异常和不可恢复异常。
不可恢复异常：通常发生在系统硬件出现了严重故障的时候，此时异常处理后系统通常面临重启，所以处理器响应不可恢复异常的机制很简单，只要立即终止当前的执行，记录软件所需的信息然后跳转到异常处理入口即可。 
可恢复异常：精确异常。要求处理完异常之后，回到产生异常的地方接着执行，还能执行正确，就好像没有发生过异常一样。发生异常的指令前面的所有指令都执行完 (修改了机器状态)，而发生异常的指令及其后面的指令都没有执行 (没有修改机器状态)。

实现精确异常的方法：
1. 任何一级流水发生异常时，在流水线中记录下发生异常的事件，直到写回阶段再处理。
2. 如果在执行阶段要修改机器状态 (如状态寄存器)，保存下来直到写回阶段再修改。
3. 指令的 PC 值随指令流水前进到写回阶段为异常处理专用。
4. 将外部中断作为取指的异常处理。
5. 指定一个通用寄存器 (或一个专用寄存器) 为异常处理时保存 PC 值专用。
6. 当发生异常的指令处在写回阶段时，保存该指令的 PC 及必需的其他状态，置取指的PC 值为异常处理程序入口地址。

## 9.5 提高流水线效率的技术
流水线 CPI = 理想 CPI + 结构相关阻塞周期数 + RAW 阻塞周期数 + WAR 阻塞周期数 + WAW 阻塞周期数 + 控制相关阻塞周期数
要想提高流水线效率 (即降低 Pipeline CPI)，可从降低理想 CPI 和降低各类流水线阻塞方面入手。

### 9.5.1 多发射数据通路 
多发射数据通路技术：让处理器中每级流水线都可以同时处理更多的指令。
1. 每一拍用 PC 从指令存储器中取两条指令；
2. 在译码级同时进行两条指令的译码、读源寄存器操作；
3. 同时执行两条指令的运算操作和访存操作，并同时写回两条指令的结果。 
双发射流水线的理想 CPI 就从单发射流水线的 1 降至 0.5。

要在处理器中支持多发射，
1. 将处理器中的各种资源翻倍，包括采用支持双端口的存储器。 
2. 增加额外的阻塞判断逻辑，当同一个时钟周期执行的两条指令存在指令相关时，也需进行阻塞。 

下图中，为了流水线控制的简化，只有同一级流水线的两条指令都不被更早的指令阻塞时，才能让这两条指令一起继续执行，所以第 6 条指令触发了陪同阻塞。
![[Pasted image 20221210191826.png]]

多发射数据通路技术虽然从理论上而言可以大幅度降低处理器的 CPI，但是由于各类相关所引起的阻塞影响，其实际执行效率大打折扣。

### 9.5.2 动态调度 
假定现在有一个双发射流水线，所有的运算单元都有两份，那么在执行下列指令序列时：
```
div.w $r3, $r2, $r1
add.w $r5, $r4, $r3
sub.w $r8, $r7, $r6
```

除法单元采用迭代算法实现，div.w 指令需要多个执行周期，与它有 RAW 相关的 add.w 指令最早也只能等到 div.w 指令执行完毕后才能开始执行。
sub.w 指令与前两条指令没有任何相关，采用动态调度的流水线就允许 sub. w 指令越过前面尚未执行完毕的 div.w 指令和 add.w 指令，提前开始执行。 

要完成上述功能，需要对原有的流水线做一些改动。 
首先要将原有的译码阶段拆分成“译码” 和 “读操作数” 两个阶段。 
1. 译码阶段进行指令译码并检查结构相关；
2. 读操作数阶段则一直等待直至操作数可以读取。 

处在等待状态的指令不能一直停留在原有的译码流水级上，否则后面的指令就没法前进。因此新增一个结构存放这些等待的指令，这个结构被称为保留站（发射队列）。
除了存储指令的功能，保留站还要负责控制其中的指令何时去执行，因此保留站中还会记录下描述指令间相关关系的信息，同时监测各条指令的执行状态。如果指令是在进入保留站前读取寄存器，那么保留站还需要监听每条结果总线，获得源操作数的最新值。

保留站在处理器中的大致位置如图 9.19 所示。
![[Pasted image 20221210192420.png]]

保留站通常组织为一个无序的队列结构，其中每一项对应一条指令，包含多个域，存放这个指令的监听结果和后续执行所需各类信息，包括有效位、指令执行控制信息 (如操作码)、源操作数的就绪状态、源操作数的监听对象以及源操作数的数据。 如果采用寄存器重命名技术，保留站中通常还要存放该指令目的寄存器重命名后的信息。

译码并读寄存器的指令进入保留站，保留站会每个时钟周期选择一条没有被阻塞的指令，送往执行逻辑，并退出保留站，这个动作称为 “发射”。

保留站调度算法的核心在于 “挑选没有被阻塞的指令”。 
从保留站在流水线所处的位置来看，保留站中的指令不可能因为控制相关而被阻塞。
结构相关所引起的阻塞的判定条件也是直观的，即检查有没有空闲的执行部件和空闲的发射端口。 但是在数据相关所引起的阻塞的处理上，存在着不同的设计思路。

WAR 相关
```
div.w $r3, $r2, $r1
add.w $r5, $r4, $r3
sub.w $r4, $r7, $r6
```
add.w 指令和 sub.w 指令之间存在 WAR 相关。
假设 sub.w 执行完毕的时候，add.w 指令因为等待 div.w 指令的结果还没有开始执行。那么 sub.w 指令如果在这个时候就修改了 r4 寄存器的值，那么等到 add.w 开始执行时，就会产生错误的结果。

WAW 相关
```
div.w $r3, $r2, $r1
add.w $r5, $r4, $r3
sub.w $r5, $r7, $r6
```
add.w 指令和 sub.w 指令之间存在 WAW 相关。
如果 sub.w 执行完毕的时候，add.w 指令因为等待 div.w 指令的结果还没有开始执行。那么 sub.w 指令若是在这个时候就修改了 r5 寄存器的值，那就会被 add. w 指令执行完写回的结果覆盖掉。sub.w 后面的指令读取 r5 寄存器会得到错误的结果。

阻塞作为解决一切冲突的普适方法肯定是可行的。 
方法：如果保留站判断出未发射的指令与前面尚未执行完毕的指令存在 WAR 和 WAW 相关，就阻塞其发射直至冲突解决。 

WAR 和 WAW 同 RAW 有本质区别，它们仅仅是由于恰好使用具有同一个名字的寄存器所引起的名字相关。
寄存器重命名技术：再找一个不受干扰的空闲寄存器，后来的一方换用这个新寄存器做中转。
例如，存在 WAR 和 WAW 相关指令序列：
```
div.w $r3, $r2, $r1
add.w $r5, $r4, $r3
sub.w $r3, $r7, $r6
mul.w $r9, $r8, $r3
```
可以通过寄存器重命名变为:
```
div.w $r3,  $r2, $r1
add.w $r5,  $r4, $r3
sub.w $r10, $r7, $r6
mul.w $r9,  $r8, $r10
```

在流水线中实现动态调度，还需要考虑精确异常。 
在乱序调度的情况下，
1. 指令已经打破了原有的先后顺序在流水线中执行，“前面” “后面” 顺序关系从哪里获得？
2. 发生异常的指令后面的指令都不能修改机器的状态，但是这些指令可能已经越过发生异常的指令先执行。

解决方法：用重排序缓冲 (ROB) 维护指令的有序结束，同时在流水线中增加一个 “提交” 阶段。 
指令对机器状态的修改只有在到达提交阶段时才能生效 (软件可见)，处于写回阶段的指令不能真正地修改机器状态，但可以更新并维护一个临时的软件不可见的机器状态。 

ROB 是一个先进先出的有序队列，所有指令在译码之后按程序顺序进入队列尾部，所有执行完毕的指令从队列头部按序提交。提交时一旦发现有指令发生异常，则 ROB 中该指令及其后面的指令都被清空。

总结实现动态调度后流水线各阶段的调整：
- 取指：不变。
- 译码：拆分为译码和读操作数两个阶段。
	1. 在读操作数阶段，把操作队列的指令根据操作类型派送到保留站 (如果保留站以及 ROB 有空)，并在 ROB 中指定一项作为临时保存该指令结果之用；
	2. 保留站中的操作等待其所有源操作数就绪后即可以被挑选出来发射到功能部件执行，发射过程中读寄存器的值和结果状态域，如果结果状态域指出结果寄存器已被重命名到 ROB，则读 ROB。
- 执行：不变。
- 写回：把结果送到结果总线，释放保留站；ROB 根据结果总线修改相应项。
- 提交：
	1. 如果队列中第一条指令的结果已经写回且没有发生异常，把该指令的结果从 ROB 写回到寄存器或存储器，释放 ROB 的相应项；
	2. 如果队列头的指令发生了异常或者转移指令猜测错误，清除操作队列以及 ROB 等。

### 9.5.3 转移预测 
通过将转移指令处理放到译码阶段和转移指令延迟槽两项技术，可以在单发射 5 级静态流水线中无阻塞地解决控制相关所引起的冲突。 但这种解决方式并不是普适的。
eg. 
1. 当为了提高处理器的主频而将取指阶段的流水级做进一步切分后，或者是采用多发射数据通路设计后，仅有 1 条延迟槽指令是无法消除流水线阻塞的。
2. 正常的应用程序中转移指令出现十分频繁，多发射结构进一步提高流水线遇到转移指令的频率。
3. 随着流水线越来越深，处理转移指令所需要的时钟周期数越来越多。 
面对这些情况，如果还是只通过阻塞流水线的方式来避免控制相关引起的冲突，将会极大地降低流水线处理器的性能。

硬件转移预测机制
基本思路：在转移指令的取指或译码阶段预测出转移指令的方向和目标地址，并从预测的目标地址继续取指令执行，这样在猜对的情况下就不用阻塞流水线。 既然是猜测，就有错误的可能。 
硬件转移预测的实现分为两个步骤: 
1. 预测：在取指或译码阶段预测转移指令是否跳转以及转移的目标地址，并根据预测结果进行后续指令的取指；
2. 确认：在转移指令执行完毕后，比较最终确定的转移条件和转移目标与之前预测的结果是否相同，如果不同则需要取消预测后的指令执行，并从正确的目标重新取指执行。

eg. 
假设平均 8 条指令中有 1 条转移指令，某处理器采用 4 发射结构，在第 10 级流水计算出转移方向和目标 (转移预测失败将产生 (10-1) ×4 = 36 个空泡)。 
1. 不进行转移预测而采用阻塞的方式，取指带宽浪费 36 / (36+8) = 82%
2. 进行转移预测：
	1. 误预测率为 50%，平均每 16 条指令预测错误一次，指令带宽浪费 36 / (36+16) = 75%
	2. 误预测率为 10%，平均每 80 条指令预测错误一次，指令带宽浪费 36 / (36+80) = 31%
	3. 误预测率为 4%，平均每 200 条指令预测错误一次，指令带宽浪费 36 / (36+200) =15%
 
那么能否设计出具有很高预测正确率的转移预测器呢? 
转移指令特性：
1. 局部性：少数转移指令的执行次数占所有转移指令执行次数中的绝大部分，这意味着只要对少量高频次执行的转移指令做出准确的预测就能获得绝大多数的性能提升；
2. 可预测性：能够通过对转移指令的行为进行分析学习得出其规律性。转移指令的可预测性主要包括单条转移指令的重复性以及不同转移指令之间存在的方向相关、路径相关。 

单条转移指令的重复性：主要与程序中的循环有关。 
1. for 型循环中转移指令的模式为 TT……TN (成功 n 次后跟 1 次不成功)；
2. while 型循环中转移指令的模式为 NN……NT (不成功 n 次后跟 1 次成功)。 

不同转移指令之间的相关性主要出现在 “ if…else…” 结构中。
图 9.20a 转移指令之间存在方向相关。两个分支的条件 (完全或部分) 基于相同或相关的信息，后面分支的结果基于前面分支的结果。 
图 9.20b 转移指令之间存在路径相关。如果一个分支是通向当前分支的前n条分支之一，则称该分支处在当前分支的路径上，处在当前分支路径上的分支与当前分支结果之间的相关性称为路径相关。
![[Pasted image 20221210195227.png]]

流水线中最早可以在取指阶段进行转移预测，此时只有 PC 信息可以用来进行预测，且预测出的信息需要同时包括转移的方向和目标地址。 
这里介绍此类预测器中一种最基本的结构———分支目标缓冲 (Branch Target Buffer，简称 BTB)。 BTB 逻辑上通常组织为一个基于内容寻址的查找表。每个表项包含 PC、跳转目标 (Target) 和饱和计数器 (Counter) 三个部分。 
BTB 的预测过程：用取指 PC 与表中各项的 PC 进行比较，如果某项置相等且该项的饱和计数器值指示预测跳转，则取出该项所存的跳转目标并跳转过去。对于那些采用 PC 相对跳转的指令，其在译码阶段就可以根据 PC 和指令码明确计算得到，因此只需要对转移方向 (即是否跳转) 进行预测。 
![[Pasted image 20221210195246.png]]

此类预测器中一种最基本的结构，即根据单条转移指令的转移历史来预测转移指令的跳转方向。
主要依据：转移指令重复性。对于重复性特征明显的转移指令 (如循环) 可以取得很好的预测效果。 

eg.
``for(i=0; i<10; i++){…}; ``
转移指令前 9 次跳转, 第 10 次不跳转。
如果我们用 1 表示跳转，0 表示不跳转，转移指令的转移模式就记为 (1111111110)。 
特点：如果上一次是跳转，那么这一次也是跳转的概率比较大。 
可以将该转移指令的执行历史记录下来用于猜测该转移指令是否跳转。这种用于记录转移指令执行历史信息的表称为转移历史表 (Branch History Table，简称 BHT)。 

最简单的 BHT 利用 PC 的低位进行索引，每项只有 1 位，记录索引到该项的转移指令上一次执行时的跳转情况，1 表示跳转，0 表示不跳转。又被称为转移模式历史表(Pattern History Table，PHT)。 

利用这种 1 位 PHT 进行预测时，
1. 根据转移指令的 PC 低位去索引 PHT，如果表项值为 1，则预测跳转，否则预测不跳转；
2. 根据该转移指令实际的跳转情况来更新对应 PHT 的表项中的值。 

仍以前面的 for 循环为例，假设 PHT 的表项初始值都为 0。
1. 转移指令第 1 次执行时，读出的表项为 0 所以预测不跳转，预测错误，第 1 次执行结束时会根据实际是跳转的结果将对应的表项值更新为 1；
2. 转移指令第 2 次执行时，从表项中读出 1 所以预测跳转，预测正确，第 2 次执行结束时会根据实际是跳转的结果将对应的表项值更新为 1；
3. …
4. 转移指令第 10 次执行时，从表项中读出 1 所以预测跳转，预测错误，第 10 次执行结束时会根据实际是不跳转的结果将对应的表项值更新为 0。 
故进入和退出循环都要猜错一次。 

这种 PHT 在应对不会多次执行的单层循环时，或者循环次数特别多的循环时还比较有效。 
但是对于如下的两重循环：

```
for(i=0;i<10;i++)
	for(j=0;j<10;j++)
	{
		…
	}
```

使用上述 1 位 PHT，则内外循环每次执行都会猜错 2 次，这样总的转移预测正确率仅有 80%。

为了提高上述情况下的转移预测正确率, 可以采用每项 2 位的 PHT。 
PHT 中每一项都是一个 2 位饱和计数器，相应的转移指令每次执行跳转就加 1 (加到 3 为止)，不跳转就减 1 (减到 0 为止)。 
预测时，如果相应的 PHT 表项的高位为 1 (计数器的值为 2 或 3) 就预测跳转，高位为 0 (计数器的值为 0 或 1) 就预测不跳转。只有连续两次猜错，才会改变预测的方向。 
使用上述 2 位 PHT 后，前面的两重循环的例子中，内层循环为 (7+81) / 100 = 88%。 
![[Pasted image 20221210195405.png]]

### 9.5.4 高速缓存
Cache 的每一个单元需要存储
1. 数据；
2. 该数据对应的内存地址 (称为 Cache 标签，Tag)；
3. 在 Cache 中的状态 (如是否有效，是否被改写等)。

处理器访问 Cache 时，除了用其中的某些位进行索引外，还要将访问地址与 Cache 中的 Tag 相比较。 
1. 如果命中，则直接对 Cache 中的内容进行访问；
2. 如果不命中，则该指令阻塞在取指或者访存阶段，同时由 Cache 失效处理逻辑完成后续处理后才能继续执行，如果是读访问那么就需要从下一层存储中取回所需读取的数据，并放置在 Cache 中。

设计 Cache 结构主要考虑 3 方面问题:
1. Cache 块索引的方式。Cache 的容量远小于内存，会涉及多个内存单元映射到同一个 Cache 单元的情况。通常分为 3 种索引方式：直接相连、全相连和组相连。
2. Cache 与下一层存储的数据关系，即写策略，分为写穿透和写回两种。存数指令需要修改下一层存储的值，
	1. 写回 Cache：将修改后的值暂时放在 Cache 中，当 Cache 替换回下一层存储时再写回。
	2. 写穿透Cache：每条存数指令都要立即更新下一层存储的值。
3. Cache 的替换策略，分为随机替换、LRU 替换和 FIFO 替换。 当发生 Cache 失效而需要取回想要的 Cache 行，此时如果 Cache 满了，则需要进行替换。进行 Cache 替换时，如果有多个 Cache 行可供替换，可以选择随机进行替换，也可以替换掉最先进入 Cache 的 Cache 行(FIFO 替换)，或者替换掉最近最少使用的 Cache 行 (LRU 替换)。

##### 映射方式
将内存和 Cache 都分为大小一样的块，假设内存有 32 项，Cache 有 8 项。
1. 直接相联：每个内存块只能放到 Cache 的一个位置上。假设要把内存的第 12 号块放到 Cache 中，因为 Cache 只有 8 项，所以只能放在第 (12 mod 8 = 4) 项上，其他地方都不能放；由此可知第 4、 12、 20、 28 号内存块都对应到 Cache 的第 4 项上，如果冲突了就只能替换。
2. 全相联：每个内存块都可以放到 Cache 的任一位置上，第 4、12、20、28 号内存块可以同时放入 Cache 中。 
3. 组相联：直接相联和全相联的折中。
	eg. 两路组相联，Cache 中第 0、2、4、6 号位置为第 0 路，第 1、3、5、7 为第 1 路，每路 4 个 Cache 块。 
	对于内存的第 12 号块，12 除以 4 余数为 0，所以既可以把第 12 号块放到 Cache 第 0 路的第 0 号位置 (即 Cache 的第 0 号位置)，也可以放到第 1 路的第 0 号位置 (即 Cache 的第 1 号位置)。

![[Pasted image 20221210214535.png]]

##### 访问Cache地址
访问 Cache 时地址可分为 3 个部分：偏移 (Offset)、索引 (Index) 和标签 (Tag)。 
1. Offset：块内地址，在地址的低位。 因为 Cache 块一般比较大，通常包含 32 字节或 64 字节，而指令或数据访问往往没有这么宽，需要通过 Offset 来指定访问对象在块内的具体位置。 
2. Index：索引 Cache 块，将其作为地址来访问 Cache。 
3. Tag：用于和 Cache 中保存的 Tag 进行比较，如果相等就给出命中信号 Hit。 

三种映射方式的地址
1. 直接相联：访问地址的 Tag 仅需要和 Index 索引的那个 Cache 块的 Tag 比较；
2. 全相联：Index 位数为 0，访问地址的 Tag 需要和每个 Cache 块的 Tag 比较，如果相等就给出命中信号 Hit，同时将命中项的 Cache 块的 Data 通过 Mux (多路选择器，Multiplexer) 选出；
3. 组相联：访问地址的 Tag 需要和每一组中 Index 索引的那个 Cache 块的 Tag 比较，生成 Hit 信号并选出命中项的 Data。

注：Offset 位数只和 Cache 块大小相关。Tag 和 Index 位数则和相联度相关。 
eg. 在 32 位处理器中，如果 Cache 大小为16KB，块大小为 32 字节，则 Offset 为 5 位，共有 512 个 Cache 块。 
1. 直接相联：Index 为 9 位，Tag 为 18 位。
2. 全相联：Index 为 0 位，Tag 为 27 位。
3. 两路组相联：Index 为 8 位，Tag 为 19 位。

![[Pasted image 20221210214441.png]]