#计算机体系结构-并行处理结构
## 11.1 多核处理器的发展演化

## 11.2 多核处理器的访存结构
通用多核处理器采用共享存储结构， 其设计存在如下关键问题：
1. 片上 Cache 如何组织？私有/共享，集中/分布？
2. 多个处理器核发出的访存指令次序如何约定？存储一致性模型。
3. 如何维护 Cache 数据一致性？Cache 一致性协议。

### 11.2.1 通用多核处理器的片上Cache结构
##### 片内Cache种类
1. 私有Cache：处理器核私有Cache，速度快，失效率高。
2. 片内共享Cache：多个处理器核共享Cache，速度稍慢，失效率低。
3. 片间共享Cache：多片共享Cache，速度慢，失效率高。（不常用）
主流多核处理器：共享最后一级Cache (LLC) 。

##### 共享LLC结构
UCA (Uniform Cache Access)
1. 集中式共享结构，多个处理器核通过总线或者交叉开关连接到最后一级Cache，所有处理器核对LLC的访问延迟相同。
2. 扩展性受限，适用于多核。

NUCA (Non-Uniform Cache Access)
1. 分布式共享结构，每个处理器核拥有本地的LLC，通过可扩展的片上互连访问其他处理器核的LLC。
2. 扩展性较好，一般采用目录Cache一致性协议，适用于众核。

![[Pasted image 20221124220318.png]]

### 11.2.2 存储一致性模型
##### 一致性问题
问题1：多机之间的数据相关。为了执行的正确，每个处理器核必须根据程序序来执行指令。
![[Pasted image 20221124221159.png]]
若P1和P2内部乱序执行，可能先LOAD再STORE。

问题2：即使每个处理器核都根据程序序执行指令，仍可能导致错误。
![[Pasted image 20221124221327.png]]
由于网络太堵，P1写回的a未传到P3，P3读到的是a的旧值0。

##### 存储一致性模型
顺序一致性模型、 处理器一致性模型、 弱一致性模型、 释放一致性模型等。 
这些存储一致性模型对访存事件次序的限制不同，因而对程序员的要求以及所能得到的性能也不一样。存储一致性模型对访存事件次序施加的限制越弱，越有利于提高性能，但编程越难。

##### 顺序一致性模型
如果在多处理机环境下的一个并行执行结果等于同一程序在单处理机多进程环境下的一个执行的结果，则此并行程序执行正确。
充分条件（GPPO条件）：
1. 在共享存储多处理机中，任一处理机都严格按照访存指令在进程中出现的次序执行，且在当前访存指令彻底执行完之前不能开始下一条访存指令。
2. store彻底完成：它所引起的值的变化已被所有处理机所接受。
3. load彻底完成：取回的值已确定，且写此值的store已彻底完成。

##### 处理器一致性模型
1. load执行前，所有在同一处理器中之前的load已完成。
2. store执行前，所有在同一处理器中之前的load和store都已完成。
允许store之后的load越过store执行。

##### 弱一致性模型
把同步操作和普通访存操作区分开来，只在同步点维护一致性。
冲突访问必须用同步操作保护。（冲突访问：两个访存操作访问的是同一单元且其中至少有一个是存数操作。）
访存次序
1. 同步操作的执行满足顺序一致性条件。
2. 在任一普通访存操作允许被执行之前，所有在同一处理机（或处理器核）中先于这一访存操作的同步操作都已完成。
3. 在任一同步操作允许被执行之前，所有在统一处理机（或处理器核）中先于这一同步操作的普通访存操作都已完成。

##### 释放一致性模型
把同步操作进一步分成获取操作acquire和释放操作release。
acquire：获取对某些共享存储单元的独占性访问权。
release：释放这种访问权。
冲突访问必须用acquire-release隔开。
访存次序
1. 同步操作的执行满足顺序一致性条件。
2. 在任一普通访存操作允许被执行之前，所有在同一处理机（处理器核）中先于这一访存操作的acquire操作都已完成。
3. 在任一release操作允许被执行之前，所有在同一处理器（处理器核）中先于这一release的普通访存操作都已完成。

### 11.2.3 Cache一致性协议
Cache一致性协议的具体作用：把某个处理器核新写的值传播给其他处理器核，以确保所有处理器核看到一致的共享存储内容。 
分类：
1. 如何传播新值：写无效 (Write-Invalidate) 协议，写更新 (Write-Update) 协议。
2. 新值将会传播给谁：侦听协议，目录协议。

##### Cache一致性协议的分类
**写无效协议，写更新协议**
写无效：当一个处理机更新某共享单位，使该共享单位的其他备份无效，当其他处理机访问该共享单位时，访问失效，再取得有效备份。
优点：独占权。
缺点：乒乓效应，即处理器核之间频繁地互相剥夺对一个共享块的访问权而导致性能严重下降。
适用：顺序共享 (Sequential Sharing) ，即在较长时间内只有一个处理器核访问一个变量。

写更新：当一个处理机更新某共享单位，把更新的内容传播给所有拥有该共享单位备份的处理机。
优点：一旦某Cache缓存了某一变量，它就一直持有此变量的最新备份，除非此变量被替换掉。
缺点：写数的处理器核每次都得把所写的值传播给其他处理器核，即使其他处理器核不再使用所写的共享块。
适用：紧密共享 (Tight Sharing) ，即多个处理器核在一段时间内频繁地访问同一变量。

**侦听协议，目录协议**
侦听协议
1. 处理器核对共享变量的访问不在Cache命中或可能引起数据不一致时，将这一事件广播到所有处理器核。
2. 系统中所有处理器核的Cache都侦听广播，当拥有广播中设计的共享变量的Cache侦听到广播后，采取相应的维持一致性的行动。
3. 每个处理器核Cache只需要维护状态信息。
适合：通过总线互连的多核处理器。

缺点：
1. 总线是一种独占式资源。
2. 总线延迟随处理器核数目增加而增加，可伸缩性差。

例子：
写无效侦听协议：当一个Cache侦听到其他处理器核欲写某一单元且自己持有此单元的备份，就使这一备份无效。
写更新侦听协议：当一个Cache侦听到自己持有备份的某一共享单元被其他处理器核更新，就根据侦听到的内容更新此备份的值。

目录协议
1. 为每一存储行维持一目录项，记录所有当前持有此行备份的处理器核号以及此行是否已被改写等信息。
2. 当一个处理器核欲往某一存储行写数且可能引起数据不一致时，它就根据目录的内容只向持有此行的备份的那些处理器核发出写使无效/写更新信号，从而避免了广播。

例子——位向量目录：
1. 每一目录项有一个 n 位的向量，其中 n 是系统中处理器核的个数。
2. 位向量中第 i 位为”1“表示此存储行在第 i 个处理器核中有备份。
3. 每一目录项还有一改写位，当改写位为 “1” 时表示某处理器核独占并已改写此行。

位向量目录的缺点是，所需的目录存储器容量随处理器核数 n 以及共享存储容量 m 的增加以 O(mn) 的速度增加，有较大存储开销。

##### Cache状态
Cache一致性协议的实现方式：在Cache中每一个Cache行设置一致性状态来记录该Cache行的读写状态，确保Cache行不会被多个处理器核同时修改。 
Cache行的一致性状态的实现有多种具体形式，如最简单的三状态ESI。

ESI：E(Exclusive, 独占), S( Shared, 共享), I( Invalid, 无效)。
Exclusive：对应Cache行被当前处理器核独占，该处理器核可以任意读写这个Cache行，而其他处理器核如果想读写这个Cache行需要请求占有这个Cache行的处理器核释放该Cache行。
Shared：当前Cache行可能被多个处理器核共享，只能读取不能写入，对其写入也会引发缓存缺失。
Invalid：当前Cache行是无效的，对其进行任何读写操作都会引发缓存缺失 (Cache Miss) 。

![[Pasted image 20221125121721.png]]

**例子——写无效的位向量目录协议**
当处理器核 Pi 发出取数操作 “LOAD x” 时，根据 x 在 Cache 和存储器中的不同状态采取相应操作: 
1. 若 x 在 Pi 的 Cache 中处于共享或独占状态，则取数操作 “ LOAD x” 在 Cache 命中。 
2. 若 x 在 Pi 的 Cache 中处于无效状态，则 Pi 向存储器发出读数请求 read(x)。 存储器收到 read(x) 后查找 x 对应的目录项。
	1. 如果 x 所在的存储行处于 CLEAN 状态 (改写位为 “0” )，即 x 在存储器的内容是有效的，那么存储器向 Pi 发出读数应答 rdack(x) 提供 x 所在行的一个有效备份，并把目录项中位向量的第 i 位置为 “1”。
	2. 如果 x 所在的存储行已被处理器核 Pk 改写 (改写位为 “1” )，
		1. 存储器向 Pk 发出一个写回请求 wtbk(x)；
		2. Pk 在收到wtbk(x) 后，把 x 在 Cache 的备份从独占状态 (EXC) 改为共享状态 (SHD)，并向存储器发出写回应答 wback(x) 提供 x 所在行的一个有效备份；
		3. 存储器收到 wback(x) 后向 Pi 发出读数应答 rdack(x) 提供 x 所在行的一个有效备份，把目录项中的改写位置为 “0” 并把位向量的第 i 位置为 “1”。 
3. 如果 x 不在 Pi 的 Cache 中，那么 Pi 先从 Cache 中替换掉一行再向存储器发出读数请求read(x)。

当处理器核 Pi 发出存数操作 “STORE x” 时，根据 x 在 Cache 和存储器中的不同状态采取相应操作：
1. 若 x 在 Pi 的 Cache 中处于独占状态，则存数操作 “ STORE x” 在 Cache 命中。 
2. 若 x 在 Pi 的 Cache 中处于共享状态，则 Pi 向存储器发出写数请求 write(x)。存储器收到 write(x) 后查找 x 对应的目录项，
	1. 如果 x 所在的存储行处于 CLEAN 状态 (改写位为 “0” )，并没有被其他处理器核所共享 (位向量中所有位都为 “0” )，那么存储器向发出请求的处理器核 Pi 发出写数应答 wtack(x) 表示允许 Pi 独占 x 所在行，把目录项中的改写位置为 “1” 并把位向量的第 i 位置为 “1”；
	2. 如果 x 所在的存储行处于 CLEAN 状态 (改写位为 “0” )，并且在其他处理器核中有共享备份 (位向量中有些位为 “1” )，
		1. 存储器根据位向量的内容向所有持有 x 的共享备份的处理器核发出一个使无效信号 invld(x)；
		2. 相应处理器核在收到 invld(x) 后把 x 在 Cache 的备份从共享状态 (SHD) 改为无效状态 (INV)，并向存储器发出使无效应答invack(x)；
		3. 存储器收到所有 invack(x) 后向 Pi 发出写数应答 wtack(x)，把目录项中的改写位置为 “1” 并把位向量的第 i 位置为 “1”，其他位清 “0”。 
3. 若 x 在 Pi 的Cache 中处于无效状态，则 Pi 向存储器发出写数请求 write(x)。存储器收到 write(x) 后查找与 x 对应的目录项，
	1. 如果 x 所在的存储行处于 CLEAN 状态 (改写位为 “0” )，并没有被其他处理器核所共享 (位向量中所有位都为 “0” )，那么存储器向发出请求的处理器核 Pi 发出写数应答 wtack(x) 提供 x 所在行的一个有效备份，把目录项中的改写位置为 “1”，并把位向量的第 i 位置为 “1”；
	2. 如果 x 所在的存储行处于 CLEAN 状态 (改写位为 “0” ) ，并且在其他处理器核中有共享备份 (位向量中有些位为 “1” ) ，
		1. 存储器根据位向量的内容向所有持有 x 的共享备份的处理器核发出一个使无效信号 invld(x) ；
		2. 相应处理器核在收到 invld(x) 后，把 x 在 Cache 的备份从共享状态 (SHD) 改为无效状态 (INV) ，并向存储器发出使无效应答invack(x)；
		3. 存储器收到所有 invack(x) 后向 Pi 发出写数应答 wtack(x) 提供 x 所在行的一个有效备份，把目录项中的改写位置为 “ 1” ，并把位向量的第 i 位置为 “ 1” ，其他位清 “0” ; 
	3. 如果 x 所在的存储行已被某个处理器核 Pk 改写 (改写位为 “1”，位向量第 k 位为 “1” )，
		1. 那么存储器向 Pk 发出一个使无效并写回请求 invwb(x)；
		2. Pk在收到 invwb(x) 后把 x 在 Cache 的备份从独占状态 (EXC) 改为无效状态 (INV) ，并向存储器发出使无效并写回应答 invwback(x) 提供 x 所在行的有效备份；
		3. 存储器收到来自 Pk 的invwback(x) 后，向 Pi 发出写数应答 wtack(x) 提供 x 所在行的一个有效备份，把目录项中的改写位置 “1” ，把位向量的第 i 位置 “ 1” ，其他位清 “ 0” 。 
4. 如果 x 不在 Pi 的 Cache 中，那么 Pi 先从 Cache 中替换掉一行再向存储器发出一个写数请求write(x) 。

## 11.3 多核处理器的互连结构
### 常见的片上互连结构
片上总线，交叉开关，片上网络。

![[Pasted image 20221125145153.png]]

共享总线结构和交叉开关结构因可伸缩性差，主要用于小规模的多核处理器。
片上网络具有可伸缩性好的优势，适合于核数较多的多核/众核处理器。

### 片上总线
概念：片上总线是片上各个部件间通信的公共通路，由一组导线组成。
优点：实现简单，易于实现广播通信。
缺点：片上总线是一种独占式资源，连接节点数越多，其总线延迟越高，每个节点分得的总线带宽越少，导致可伸缩性不好。 
适合：连接节点不多的场合，常用于处理器核不多的多核处理器中。

### 交叉开关
概念：可以看作一个以矩阵形式组织的开关集合。 在一个 M 个输入、N 个输出的交叉开关中，每个输出端口都可以接任意输入端口。 
优点：高带宽，多对输入与输出端口间可以并行通信，且总带宽随所连接节点数的增加而增加。 
缺点：随着连接节点数的增加，交叉开关需要的交叉点数目增加较快，物理实现代价较高，复杂度为 O(M×N)，因此可伸缩性有限，也不适合连接节点数多的情况。 
例如，一个 M 个输入端口和 N 个输出端口的交叉开关，要增加成 M+1 输入端口和 N+1 个输出端口的交叉开关，则需要增加 M+N+1 个交叉点。
适合：可伸缩网络的节点内部。

### 片上网络
概念：
1. 处理器核抽象成节点，互联网络用来在处理器核节点间传输消息数据。
2. 数据封装成数据包，通过路由器之间的分组交换和对应的存储-转发机制来实现处理器核间的通信。

##### 拓扑结构
片上网络由节点和传输信道的集合构成。片上网络的拓扑指网络中节点和信道的排列方式。
环、网格是最常见的两种片上网络拓扑结构。

##### 路由算法
片上网络采用的路由方法决定了数据包从源节点到目的节点的传输路径。
路径是传输信道的集合，即 P = {c1, c2, ... ,ck}，其中当前信道ci的输出节点与下一条信道ci+1的输入节点相同。
在某些片上网络拓扑结构中（如环），从某个源节点出发到目的节点的路径只有唯一的一条；而某些结构（如Mesh），可能有多条路径。

Mesh网络的寻路算法
1. 维序路由：先选一个维度的方向传输，当此维度走到与目的地址相同维度方向后，再改变到其他维度，比如先沿X方向走到头，再沿Y反向。
2. 全局自适应路由：在每个节点有多种方向选择时，优先选择负载较轻的节点方向作为路径，可以解决局部负载不均衡的情况。

##### 路由器结构
路由器由寄存器，交叉开关，功能单元和控制逻辑组成。
路由器将数据包从输入端口存储转发到输出端口发送出去。

缓冲区：节点的每一个输入端口有一个独立的缓冲区，在数据包可以获得下一跳资源离开之前，缓冲区将它们存储下来。
交叉开关：连接输入端口的缓冲区和输出端口，控制数据包传输到指定输出端口。
分配器：包括路由计算、虚通道分配和交叉开关分配三种功能。
路由计算：计算head flit下一跳输出方向。
虚通道分配：分配flit在缓冲队列的位置。
交叉开关分配：仲裁竞争的flit中哪个可以获得资源传输到输出端口。

![[Pasted image 20221125162502.png]]

数据包传输的流水级
数据包：切分为head flit和body flit
路由器的四个流水级：路由计算 (RC)，虚通道分配 (VA)，交叉开关分配 (SA)，交叉开关上传输 (ST)。
head flit：必须经历四个流水级RC，VA，SA，ST。
body flit：依次经历SA，ST。

##### 流量控制
流量控制用来组织每个处理器核节点中有限的共享资源。
片上网络的主要资源是信道 (Channel) 和缓冲区 (Buffer)。 
1. 信道：用来传输节点之间的数据包。 
2. 缓冲区：节点上的存储装置，比如寄存器、内存等，用来临时存储经过节点的数据包。当网络拥塞时，数据包需要临时存在缓冲区中等待传输。 

好的流量控制策略
1. 公平性：不公平的流量控制极端情况会导致某些数据包陷入无限等待状态。
2. 无死锁：死锁是当一些数据包互相等待彼此释放资源而造成的无限阻塞的情况。

例：基于信用的流量控制
1. 缓冲队列：每个处理器核节点的输入端口有自己的缓冲区队列，分别用来存取来自对应的上一跳节点的数据，比如 i+1 号节点最左侧的 Buffer 用来存储来自 i 号节点的数据包。
2. 计数器：每个节点上对应其相邻的节点都有一个计数器, 分别是 S\[0\] ~ S\[3\], 用来记录相邻节点内缓冲区Buffer的使用情况。

节点 i 
1. 每一个计数器的初始状态 S\[0-3\] 都设为 0；
2. 当它向相邻节点如 i+1 号节点发送 flit 时，首先判断 S\[0\] 的值是否已达到 Buffer 的最大值，
	1. 如果 S\[0\] 未达到最大值，则将 S\[0\] 的值加 1，然后将 flit 发送过去；
	2. 如果 S\[0\] 已经达到最大值，则数据会被扣留在 Buffer中直到右侧节点有足够的空间收留来自它的数据。 

 节点 i+1
 1. 每当它左侧的 Buffer 送走一个 flit 时，它就向其左侧的节点发送一个 Credit 信号，通知左侧节点，此 Buffer 已多出一个空余位置。
 2. 当左侧节点收到此 Credit 信号后，则会更新对应的 S\[0\] 减1。

## 多核处理器的同步机制
常见的同步机制包括锁操作、栅障操作和事务内存。 
锁操作和事务内存主要用于保护临界区，栅障操作用于实现全局同步。 
锁操作和栅障操作属于传统同步方法，广泛用于并行系统中，事务内存则是适应多核处理器设计需求的一种新同步机制。 
同步机制一般建立在用户级软件例程(Routine)上，软件例程主要基于硬件提供的同步指令实现。

### 原子操作
##### ”读-改-写“原子指令
1. Test_and_Set：取出内存中对应地址的值，同时对该内存地址赋予一个新的值。
2. Swap：交换两个内存位置的值。
3. Compare_and_Swap：取出内存中对应地址的值和另一个给定值 A 进行比较，如果相等，则将另一个给定值 B 写入这个内存地址，否则不进行写操作。
4. Fetch_and_Op：在读取内存对应地址值的同时将该地址的值进行一定的运算再存回。根据运算操作 (Op) 的不同，有许多种不同的实现形式。例如：Fetch_and_Increment 指令就是读取指定地址的值，同时将该值加1并写回内存。 
可以看出 “读-改-写” 原子指令和内存的交互过程至少有两次，一次读内存，另一次写内存，而两次交互过程之间往往还有一些比较、加减之类的运算操作。

##### LL/SC原子指令对
1. LL 指令将对应地址的内存数据读入寄存器，并置系统中LLbit为1。
2. 对该寄存器中的值进行任意的运算。
3. LLbit为1时，处理器检查相应单元是否被修改，如果其他处理器或设备访问了相应单元或执行了ERET操作，LLbit置0。
4. 使用 SC 指令尝试将运算后的数据存回内存对应的地址。 
5. 当且仅当 LL 指令完成之后没有其他对该地址内存数据的修改操作，即LLbit=1，则 SC 指令执行成功并返回一个非零值，运算后的数据顺利写回内存；否则 SC 指令执行失败并返回值 0，修改后的数据不会被写回内存，也不会产生任何对内存的改动。 
6. SC 指令失败后一般需要重新执行上述过程, 直到 SC 指令成功为止。 
SC 指令的成功说明了 LL / SC 指令之间没有其他对同一地址的写入操作，也就保证了 LL / SC 指令之间的不可分割性。 

优点：设计简单，每条指令只需和内存交互一次，且在 LL 指令和 SC 指令之间可以加入任意的运算指令，可以灵活地实现类似于 “读-改-写” 的复杂原子操作。 
缺点：密集共享时，SC 不容易成功。
优化措施：LL 访问时把相应 Cache 行置为EXC 状态，而不是 SHD 状态，提高 SC 成功的概率。 
相对于 Test_and_Set 指令和 Fetch_and_Op 指令等实现复杂的单条原子指令，LL / SC 指令对成为目前最常见的原子指令，被多种现代 RISC 指令系统所采用。

### 锁的软件实现方法
锁 (Lock) 是并行程序中常用的对多个线程共享的临界区 (Critical Section) 进行保护的同步操作。
自旋锁 (Spin Lock) 是锁操作的一种最基本的实现形式。 
Test_and_Set 自旋锁是最简单的自旋锁，通过使用 Test_and_Set 原子指令来完成锁的获取、等待和查询。 

```
// Test_and_Set
void acquire_lock()
{
	while(Test_and_Set(lock)!=0);  // 如果不是0，自旋等待
	critical_section();
}

void release_lock()
{
	lock=0;  // 释放锁
}
```

假设 1 表示锁被占用，0 表示锁空闲，Test_and_Set步骤如下： 
1. 处理器使用 Test_and_Set 原子指令读取锁变量的值，同时将锁变量的值改为 1。 
2. 如果读取到锁的值为 0，说明锁空闲，该处理器成功获得锁。 
	由于 Test_and_Set 指令已经将锁的值同时改为了 1，所以其他处理器不可能同时获得这把锁。 
3. 如果读取到锁的值为 1，说明已经有其他处理器占用了这把锁，则该处理器循环执行 Test_and_Set 指令自旋等待，直到成功获得锁。
	由于锁的值已经是 1 ，Test_and_Set 指令再次将锁的值设为 1，锁的值并未变化，所以不会影响到锁操作的正确性。 
4. 当获得锁的处理器打算释放锁时，只需要执行一条普通的 store 指令，将锁的值设置为 0 即可。由于一次只能有一个处理器核获得锁，所以不用担心多个处理器核同时释放锁而引发访存冲突，故不需要使用原子指令来释放锁。

缺点：当一个处理器核获得锁以后，其他等待的处理器核会不断循环执行 Test_and_Set 指令访问锁变量，试图获取锁权限，从而在片上互连上产生大量的访存通信。
优化方法：Test_and_Set 指令之间加入一定的延迟，减少等待阶段 Test_and_Set 原子指令自旋执行的次数以减轻访存的压力。 

### 栅障软件实现方法
栅障 (Barrier) 是并行程序中常用的同步操作。 
栅障要求处理器核等待，一直到所有处理器核都到达栅障后，才能释放所有处理器核继续执行。 
栅障有多种实现方式，下面主要介绍比较简单的集中式栅障。 

集中式栅障
1. 在共享存储中设置一个共享的栅障变量。 
2. 每当一个处理器核到达栅障以后，就使用原子指令修改栅障值表示自己已经到达 (如将栅障的值加 1)，然后对该栅障值进行自旋等待。
3. 当栅障的值表明所有处理器核都已经到达 (即栅障的值等于预计到达的总的处理器核的数量) 时，栅障操作顺利完成，所有自旋等待的处理器核就可以继续往下执行。 

```
barrier()
{
	Fetch_and_Inc(count);
	while(count!=Max);
}
```

优点：实现简单、灵活，可以支持各种类型的栅障。
缺点：每一个到达的处理器核都需要对同一个共享的栅障值进行一次修改以通告该处理器核到达栅障，已到达栅障的处理器核会不断访问栅障值以判断栅障是否完成。这会在片上互连上产生许多无用的访存通信，并且随着处理核数的增加，栅障的时间和无用的访存数量都会快速增长，可扩展性不好。
优化：在查询操作之中增加一些延迟。 加入延迟虽然可以减少一些网络带宽的浪费，但是也可能降低栅障的性能。针对集中式栅障的弱点，研究人员提出了软件合并树栅障等优化方法。

### 事务内存
定义：访问共享变量的代码区域声明为一个事务 (Transaction)，事务执行并原子地提交所有结果到内存 (如果事务成功)，或中止并取消所有的结果 (如果事务失败)。 

性质：
1. 原子性 (Atomicity)，即事务中的所有指令要么执行要么不执行。
2. 一致性 (Consistency)，即任何时刻内存处于一致的状态。
3. 隔离性 ( Isolation)，即事务不能看见其他未提交事务涉及的内部对象状态。 

事务内存实现的关键部分：
1. 冲突检测：确定事务并发执行过程中是否存在数据的冲突访问。 
2. 冲突解决：在发生冲突时决定继续或者放弃事务的执行。
	1. 如果支持事务的暂停操作，可以暂停引起冲突的事务，直到被冲突的事务执行结束；
	2. 如果不支持事务的暂停操作，就必须在引起冲突的事务中选择一个提交，同时放弃其他事务的执行。
3. 事务的提交或放弃：解决事务冲突的核心步骤。事务提交需要将结果数据更新到内存系统中，事务放弃需要将事务的结果数据全部丢弃。

事务内存实现方式：
1. 软件事务内存：通过软件实现，不需要底层硬件提供特殊的支持，主要以库函数或者编程语言形式实现。 
2. 硬件事务内存：主要对多核处理器的 Cache 结构进行改造。
软件事务内存实现灵活，更容易集成到现有系统中，但性能开销大。
硬件事务内存需要修改硬件，但是性能开销小，程序整体执行性能高。 

例：Intel TSX (Transactional Synchronization Extensions) 是 Intel 公司针对事务内存的扩展实现，提出了一个针对事务内存的指令集扩展，主要包括 3 条新指令：XBEGIN、XEND 和 XABORT。
1. XBEGIN 指令启动一个事务，并提供了如果事务不能成功执行的回退地址信息；
2. XEND 指令表示事务的结束；
3. XABORT 指令立刻触发一个中止，类似于事务提交不成功。 
硬件实现以 Cache 行为单位，跟踪事务的读集 (Read-Set) 和写集 (Write-Set)。 
如果事务读集中的一个 Cache 行被另一个线程写入，或者事务的写集中的一个 Cache 行被另一个线程读取或写入，则事务就遇到冲突 (Conflict)，通常导致事务中止。

## 典型多核处理器