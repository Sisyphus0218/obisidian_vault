2020K8009929017 侯昱帆

1.关于多核处理器的 Cache 结构，请介绍 UCA 与 NUCA 的特点。
答：
UCA (Uniform Cache Access)
1. 集中式共享结构，多个处理器核通过总线或者交叉开关连接到最后一级Cache，所有处理器核对LLC的访问延迟相同。
2. 扩展性受限，适用于多核。

NUCA (Non-Uniform Cache Access)
1. 分布式共享结构，每个处理器核拥有本地的LLC，通过可扩展的片上互连访问其他处理器核的LLC。
2. 扩展性较好，一般采用目录Cache一致性协议，适用于众核。

[[../notes/第11章 多核处理器结构#共享LLC结构]]

2.有两个并行执行的线程，在顺序一致性和弱一致性下，它各有几种正确的执行顺序？给出执行次序和最后的正确结果 (假设 X，Y 的初始值均为0)。
```
P1
X=1;
print Y;

P2
Y=1;
print X;
```
答：
顺序一致性
```
X=1;
print Y;
Y=1;
print X;
结果 Y=0, X=1

X=1;
Y=1;
print Y;
print X;
结果 Y=1, X=1

X=1;
Y=1;
print X;
print Y;
结果：X=1, Y=1

Y=1;
print X;
X=1;
print Y;
结果：X=0, Y=1

Y=1;
X=1;
print X;
print Y;
结果：X=1, Y=1

Y=1;
X=1;
print Y;
print X;
结果：Y=1, X=1
```

弱一致性：如果在print Y，print X处加上同步，则
```
X=1;
Y=1;
print Y;
print X;
结果 Y=1, X=1

X=1;
Y=1;
print X;
print Y;
结果：X=1, Y=1

Y=1;
X=1;
print X;
print Y;
结果：X=1, Y=1

Y=1;
X=1;
print Y;
print X;
结果：Y=1, X=1
```

[[../notes/第11章 多核处理器结构#顺序一致性模型]] [[../notes/第11章 多核处理器结构#弱一致性模型]]

>顺序一致性：每个线程的语句顺序为线性，线程之间的序未约定。
>(此题 `X=1` 必须在 `print Y` 前；`Y=1` 必须在 `print X` 前。
>打印：(Y)0(X)1/ (Y)1(X)1 /(X)1(Y)1 /(Y)1(X)1 /(X)1(Y)1 /(X)0(Y)1
>弱一致性：没有显式同步时，Load和Store之间亦没有序的约定，故四条语句的任意执行序都是可能的。结果也包含所有可能情况，还可以打印出 X=0 和 Y=0，因为可以先 print X 和 Y，再执行 X=1 和 Y=1。

3.关于 Cache 一致性协议，MESI 协议比 ESI 协议增加了 M 状态，请解释有什么好处。
答：减少了 Cache 到内存的数据传输次数，Cache 只需要将 Modified 状态的 Cache 行写回内存。
[[../notes/第11章 多核处理器结构#Cache状态]]

>Modified状态表示当前cache块被当前处理器核独占并已经被修改过了，在写回时只需要将M状态的cache块写回内存中，可以减少写回的访存量。

4.请分别采用 Fetch_and_Increment 和 Compare_and_Swap 原子指令编写实现自旋锁的代码，并分析可能的性能改进措施。
答：
```
// Fetch_and_Increment
void acquire_lock()
{
	while(lock!=0);
	Fetch_and_Increment(lock);  // when lock==0, only one cpu core can fetch the lock
	critical_section();
}

void release_lock()
{
	lock=0;
}
```

```
// Compare_and_Swap
void acquire_lock()
{
	while(Compare_and_Swap(lock, 0, 1)!=0);  // if lock==0, lock=1; else do nothing
	critical_section();
}

void release_lock()
{
	lock=0;  
}
```

缺点：一个处理器核获得锁后，其他处理器核循环访问锁变量试图获取锁，从而在片上互连产生大量的访存通信。
改进：在自旋间加入一定的延迟，减少等待阶段自旋执行的次数以减轻访存的压力。 

[[../notes/第11章 多核处理器结构#锁的软件实现方法]]

>标准答案如下

```
获取锁：
while(Fetch_and_Increment(lock));
<critical_section>
释放锁：
lock=0;
(存在的问题：lock溢出）

改进：定序
myid=new of Fetch_and_Increment(lock);  // new of: Fetch_and_Increment执行之后的lock值
while(myid!=lock);  // 如果没有抢到锁，只能等待，如果抢到锁就可以继续执行
<critical_section>
lock--;  // 执行完后，让前一个线程执行
```

```
获取锁：
while(!Compare_and_Swap(lock,0,1));
<critical_section>
释放锁：
lock=0;
```

5.在共享存储的多处理器中，经常会出现假共享现象。 假共享是由于两个变量处于同一个Cache 行中引起的，会对性能造成损失。为了尽量减少假共享的发生，程序员在写程序时应该注意什么？
答：需要注意尽量避免将彼此无关的变量放到同一缓存行中，可以采用缓存行填充的方法：
1. 考虑变量之间的关系，比如哪些变量是独立变化的，哪些变量是协同变化的。将协同变化的变量分在一组，将无关的变量分到不同组。
2. 在变量前后填充额外的占位变量，避免不同组的数据被分到同一个缓存行中。
<[面试官：什么是伪共享，如何避免？ - 简书 (jianshu.com)](https://www.jianshu.com/p/16334db349fc)>

>假共享：额外的invalid导致额外总线访问和高延迟
>各线程需要经常访问或同时访问的变量不混放在同一cache行
>数组等确需共享访问的，应安排好访问顺序以减少冲突

6.请介绍片上网络路由器设计中的虚通道概念，并说明采用虚通道有什么好处。
答：一个虚通道是路由器中一个独立的队列，多个虚通道共享两个路由器之间的物理连线。
当某个虚通道被阻塞，其他包可以通过其他虚通道来穿过其他物理连接。因此虚通道可以提高物理连接的利用率并且提升整个网络的吞吐率。
<[片上网络 On Chip Networks V - 简书 (jianshu.com)](https://www.jianshu.com/p/fe797ccd4e42)>

[[../notes/第11章 多核处理器结构#路由器结构]]

>一个物理通道可包含多个虚通道，每个虚通道包含独立的缓冲区和状态标识，物理通道选择一个虚通道的数据进行传输
>当某个虚通道阻塞时，可切换至其他虚通道进行传输，从而提高了整体吞吐率。

7.分析 Fermi GPU 的存储结构，指出不同层次存储结构的带宽、延迟，以及是否共享。
答：

| 存储结构    | 带宽      | 延迟           | 共享    | 
| ---        | ---       | ---            |---     |
| SM 寄存器堆 | 8000 GB/s | 1 cycle        | 不共享 |
| 共享存储    | 1000 GB/s | 20-30 cycles   | 共享   |
| L1 Cache   | 1000 GB/s | 20-30 cycles   | 不共享 |
| L2 Cache   |           |                | 共享   |
| 主存储      | 177 GB/s  | 400-800 cycles | 共享   |